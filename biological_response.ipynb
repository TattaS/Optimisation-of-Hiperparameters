{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML-7. ПРОГНОЗИРОВАНИЕ БИОЛОГИЧЕСКОГО ОТВЕТА (HW-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Задача "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Необходимо предсказать биологический ответ молекул (столбец 'Activity') по их химическому составу (столбцы D1-D1776)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Описание данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные представлены в формате CSV.  Каждая строка представляет молекулу. \n",
    "\n",
    "* Первый столбец Activity содержит экспериментальные данные, описывающие фактический биологический ответ [0, 1]; \n",
    "* Остальные столбцы D1-D1776 представляют собой молекулярные дескрипторы — это вычисляемые свойства, которые могут фиксировать некоторые характеристики молекулы, например размер, форму или состав элементов.\n",
    "Предварительная обработка не требуется, данные уже закодированы и нормализованы.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Описание задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо обучить две модели: логистическую регрессию и случайный лес. Далее нужно сделать подбор гиперпараметров с помощью базовых и продвинутых методов оптимизации. Важно использовать все четыре метода (GridSeachCV, RandomizedSearchCV, Hyperopt, Optuna) хотя бы по разу, максимальное количество итераций не должно превышать 50.\n",
    "\n",
    "В качестве метрики будем использовать F1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5014/1784025545.py:21: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np #для матричных выражений\n",
    "import pandas as pd #для обработки и анализа данных\n",
    "import matplotlib.pyplot as plt #визуализация\n",
    "import seaborn as sns #визуализация\n",
    "import hyperopt #продвинутая оптимизация гиперпараметров модели\n",
    "import optuna #продвинутая оптимизация гиперпараметров модели\n",
    "\n",
    "\n",
    "from sklearn import linear_model #линейные модели\n",
    "from sklearn import tree #деревья решений\n",
    "from sklearn import ensemble #ансамбли\n",
    "from sklearn import metrics #метрики\n",
    "from sklearn import preprocessing #предобработка данных\n",
    "from sklearn.model_selection import train_test_split #сплитирование данных\n",
    "from sklearn.model_selection import GridSearchCV #оптимизация гиперпараметров модели\n",
    "from sklearn.model_selection import RandomizedSearchCV #оптимизация гиперпараметров модели\n",
    "from sklearn.model_selection import cross_val_score #кросс-валидация\n",
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Загрузка и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>...</th>\n",
       "      <th>D1767</th>\n",
       "      <th>D1768</th>\n",
       "      <th>D1769</th>\n",
       "      <th>D1770</th>\n",
       "      <th>D1771</th>\n",
       "      <th>D1772</th>\n",
       "      <th>D1773</th>\n",
       "      <th>D1774</th>\n",
       "      <th>D1775</th>\n",
       "      <th>D1776</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497009</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132956</td>\n",
       "      <td>0.678031</td>\n",
       "      <td>0.273166</td>\n",
       "      <td>0.585445</td>\n",
       "      <td>0.743663</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.606291</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111209</td>\n",
       "      <td>0.803455</td>\n",
       "      <td>0.106105</td>\n",
       "      <td>0.411754</td>\n",
       "      <td>0.836582</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.033300</td>\n",
       "      <td>0.480124</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209791</td>\n",
       "      <td>0.610350</td>\n",
       "      <td>0.356453</td>\n",
       "      <td>0.517720</td>\n",
       "      <td>0.679051</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538825</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.196344</td>\n",
       "      <td>0.724230</td>\n",
       "      <td>0.235606</td>\n",
       "      <td>0.288764</td>\n",
       "      <td>0.805110</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.517794</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.494734</td>\n",
       "      <td>0.781422</td>\n",
       "      <td>0.154361</td>\n",
       "      <td>0.303809</td>\n",
       "      <td>0.812646</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1777 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Activity        D1        D2    D3   D4        D5        D6        D7  \\\n",
       "0         1  0.000000  0.497009  0.10  0.0  0.132956  0.678031  0.273166   \n",
       "1         1  0.366667  0.606291  0.05  0.0  0.111209  0.803455  0.106105   \n",
       "2         1  0.033300  0.480124  0.00  0.0  0.209791  0.610350  0.356453   \n",
       "3         1  0.000000  0.538825  0.00  0.5  0.196344  0.724230  0.235606   \n",
       "4         0  0.100000  0.517794  0.00  0.0  0.494734  0.781422  0.154361   \n",
       "\n",
       "         D8        D9  ...  D1767  D1768  D1769  D1770  D1771  D1772  D1773  \\\n",
       "0  0.585445  0.743663  ...      0      0      0      0      0      0      0   \n",
       "1  0.411754  0.836582  ...      1      1      1      1      0      1      0   \n",
       "2  0.517720  0.679051  ...      0      0      0      0      0      0      0   \n",
       "3  0.288764  0.805110  ...      0      0      0      0      0      0      0   \n",
       "4  0.303809  0.812646  ...      0      0      0      0      0      0      0   \n",
       "\n",
       "   D1774  D1775  D1776  \n",
       "0      0      0      0  \n",
       "1      0      1      0  \n",
       "2      0      0      0  \n",
       "3      0      0      0  \n",
       "4      0      0      0  \n",
       "\n",
       "[5 rows x 1777 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/home/tatiana/ML/Hiperparameters setting/_train_sem09 (1).csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Activity    0\n",
       "D1          0\n",
       "D2          0\n",
       "D3          0\n",
       "D4          0\n",
       "           ..\n",
       "D1772       0\n",
       "D1773       0\n",
       "D1774       0\n",
       "D1775       0\n",
       "D1776       0\n",
       "Length: 1777, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#проверка наличия пропусков\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#проверка сбалансированности классов целевого признака\n",
    "sns.countplot(data=data, x='Activity');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: Признак несбалансирован. Требуется стратифицированное разделение данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создаем матрицу наблюдений X и вектор ответов y\n",
    "X = data.drop(['Activity'], axis=1)\n",
    "y = data['Activity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Разделяем выборку на тренировочную и тестовую в соотношении 80/20. Для сохранения соотношений целевого признака используем параметр stratify (стратифицированное разбиение).\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3000, 1776), (751, 1776))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Оптимизация гиперпараметров модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Логистическая регрессия**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зафиксируем только метрики, которые были получены без дополнительной настройки, т.е со значениями гиперпараметров, установленных по умолчанию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score на тестовом наборе: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Создаем объект класса логистическая регрессия\n",
    "log_reg = linear_model.LogisticRegression(max_iter = 50)\n",
    "#Обучаем модель, минимизируя logloss\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_test_pred = log_reg.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Случайный лес**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зафиксируем только метрики, которые были получены без дополнительной настройки, т.е со значениями гиперпараметров, установленных по умолчанию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score на тестовом наборе: 0.80\n"
     ]
    }
   ],
   "source": [
    "#Создаем объект класса случайный лес\n",
    "rf = ensemble.RandomForestClassifier(random_state=42)\n",
    "\n",
    "#Обучаем модель\n",
    "rf.fit(X_train, y_train)\n",
    "#Выводим значения метрики \n",
    "y_train_pred = rf.predict(X_train)\n",
    "# print('Train: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "y_test_pred = rf.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение метрики для модели случайного леса лучше.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем оптимизировать гиперпараметры моделей и сравним результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **GridSearchCV - Логистическая регрессия**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.76 s, sys: 203 ms, total: 2.97 s\n",
      "Wall time: 15.5 s\n",
      "f1_score на тестовом наборе: 0.78\n",
      "Наилучшие значения гиперпараметров: {'penalty': 'l2', 'solver': 'saga'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#указываем имена искомых гиперпараметров и их тестируемые значения в виде словаря\n",
    "\n",
    "param_grid = {'penalty': ['l2', 'none'] ,#тип регурялизации\n",
    "              'solver': ['lbfgs', 'saga'], #алгоритм оптимизации\n",
    "              }\n",
    "#передаем модель, словарь гиперпараметров, количество фолдов для кросс-валидации и указываем n_jobs=-1, чтобы использовать все ядра\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=linear_model.LogisticRegression(\n",
    "        random_state=42, #генератор случайных чисел\n",
    "        max_iter=50 #количество итераций на сходимость\n",
    "    ), \n",
    "    param_grid=param_grid, \n",
    "    cv=5, \n",
    "    n_jobs = -1\n",
    ")  \n",
    "%time grid_search.fit(X_train, y_train) \n",
    "y_test_pred = grid_search.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения метрики не изменились, но это значит лишь, что мы не нашли комбинацию внешних параметров лучше, чем заданы по умолчанию. Это не удивительно и достаточно часто исходные  гиперпараметры дают неплохой результат, но это не повод останавливаться.\n",
    "Попробуем расширить сетку гиперпараметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.95 s, sys: 165 ms, total: 5.11 s\n",
      "Wall time: 1min 40s\n",
      "f1_score на тестовом наборе: 0.79\n",
      "Наилучшие значения гиперпараметров: {'C': 0.3, 'penalty': 'l1', 'solver': 'saga'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "param_grid = [\n",
    "              {'penalty': ['l2', 'none'] , # тип регуляризации\n",
    "              'solver': ['lbfgs', 'sag'], # алгоритм оптимизации\n",
    "               'C': [0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1]}, # уровень силы регурялизации\n",
    "              \n",
    "              {'penalty': ['l1', 'l2'] ,\n",
    "              'solver': ['liblinear', 'saga'],\n",
    "               'C': [0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1]}\n",
    "]\n",
    "grid_search_1 = GridSearchCV(\n",
    "    estimator=linear_model.LogisticRegression(random_state=1, max_iter=50), \n",
    "    param_grid=param_grid, \n",
    "    cv=5, \n",
    "    n_jobs = -1\n",
    ")  \n",
    "%time \n",
    "grid_search_1.fit(X_train, y_train) \n",
    "y_test_pred = grid_search_1.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(grid_search_1.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшее значение точности при кросс-валидаци: 0.76\n"
     ]
    }
   ],
   "source": [
    "print(\"Наилучшее значение точности при кросс-валидаци: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.453286</td>\n",
       "      <td>0.158629</td>\n",
       "      <td>0.059024</td>\n",
       "      <td>0.019423</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.793333</td>\n",
       "      <td>0.776667</td>\n",
       "      <td>0.736667</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.762333</td>\n",
       "      <td>0.021592</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.226830</td>\n",
       "      <td>0.317193</td>\n",
       "      <td>0.031626</td>\n",
       "      <td>0.002658</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l2', 'solver': 'sag'}</td>\n",
       "      <td>0.795000</td>\n",
       "      <td>0.776667</td>\n",
       "      <td>0.736667</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.762667</td>\n",
       "      <td>0.022076</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       1.453286      0.158629         0.059024        0.019423    0.01   \n",
       "1       4.226830      0.317193         0.031626        0.002658    0.01   \n",
       "\n",
       "  param_penalty param_solver                                           params  \\\n",
       "0            l2        lbfgs  {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}   \n",
       "1            l2          sag    {'C': 0.01, 'penalty': 'l2', 'solver': 'sag'}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.793333           0.776667           0.736667              0.765   \n",
       "1           0.795000           0.776667           0.736667              0.765   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0               0.74         0.762333        0.021592                5  \n",
       "1               0.74         0.762667        0.022076                4  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Взглянем на результаты кросс-валидации\n",
    "result_cv = pd.DataFrame(grid_search_1.cv_results_)\n",
    "result_cv.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x396 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# отрисуем, как менялась точность при различных гиперпараметрах\n",
    "visual = pd.pivot_table(pd.DataFrame(grid_search_1.cv_results_),\n",
    "                        values='mean_test_score', index='param_C',\n",
    "                        columns='param_solver')\n",
    "sns.heatmap(visual)\n",
    "plt.title('Тепловая карта зависимости метрики accuracy от solver и С') # подпись графика\n",
    "sns.set(rc={'figure.figsize':(12, 8)}) #задаем размер графика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что наилучший резултат дает алгоритм saga в сочетании с уровнем регуляризации 0,3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика улучшилась незначительно, хотя время потратили гораздо больше.\n",
    "Поиск по сетке не гарантирует, что мы найдем наилучшую комбинацию гиперпараметров, а все потому что сетка значений конечна и наилучшее значение может оказаться между заданными нами значений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **GridSearchCV - Случайный лес**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.21 s, sys: 105 ms, total: 2.32 s\n",
      "Wall time: 35.2 s\n",
      "f1_score на тестовом наборе: 0.80\n",
      "Наилучшие значения гиперпараметров: {'max_depth': 20, 'min_samples_leaf': 5, 'n_estimators': 140}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_estimators': list(range(80, 200, 30)),\n",
    "            'min_samples_leaf': [5],\n",
    "            'max_depth': list(np.linspace(20, 40, 5, dtype=int))\n",
    "            }\n",
    "            \n",
    "grid_search_forest = GridSearchCV(\n",
    "    estimator=ensemble.RandomForestClassifier(random_state=42), \n",
    "    param_grid=param_grid, \n",
    "    cv=5, \n",
    "    n_jobs = -1\n",
    ")  \n",
    "%time grid_search_forest.fit(X_train, y_train) \n",
    "y_train_pred = grid_search_forest.predict(X_train)\n",
    "y_test_pred = grid_search_forest.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(grid_search_forest.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для случайного леса метрика осталась без изменений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **RandomizedSearchCV - Логистическая регрессия**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.39 s, sys: 206 ms, total: 2.59 s\n",
      "Wall time: 21.1 s\n",
      "f1_score на тестовом наборе: 0.78\n",
      "Наилучшие значения гиперпараметров: {'solver': 'sag', 'penalty': 'l2', 'C': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tatiana/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#np.linspace(start(от), stop(до), num=50(количество),dtype- тип данных)\n",
    "param_grid = {'penalty': ['l2', 'none'] ,\n",
    "              'solver': ['lbfgs', 'sag'],\n",
    "               'C': list(np.linspace(0.01, 1, 10, dtype=float))},\n",
    "            \n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=linear_model.LogisticRegression(random_state=42, max_iter=50), \n",
    "    param_distributions=param_grid, \n",
    "    cv=5, \n",
    "    n_iter = 10, \n",
    "    n_jobs = -1\n",
    ")  \n",
    "%time random_search.fit(X_train, y_train) \n",
    "y_test_pred = random_search.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(random_search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **RandomizedSearchCV - Случайных лес**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.72 s, sys: 63.3 ms, total: 2.79 s\n",
      "Wall time: 20.3 s\n",
      "f1_score на тестовом наборе: 0.80\n",
      "Наилучшие значения гиперпараметров: {'n_estimators': 170, 'min_samples_leaf': 5, 'max_depth': 22}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_estimators': list(range(80, 200, 30)),\n",
    "              'min_samples_leaf': [5],\n",
    "              'max_depth': list(np.linspace(20, 40, 10, dtype=int))\n",
    "              }\n",
    "            \n",
    "random_search_forest = RandomizedSearchCV(\n",
    "    estimator=ensemble.RandomForestClassifier(random_state=42), \n",
    "    param_distributions=param_grid, \n",
    "    cv=5,\n",
    "    n_iter = 10, \n",
    "    n_jobs = -1\n",
    ")  \n",
    "%time random_search_forest.fit(X_train, y_train) \n",
    "y_train_pred = random_search_forest.predict(X_train)\n",
    "y_test_pred = random_search_forest.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(random_search_forest.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы: \n",
    "1. Методами базовой оптимизации не удалось существенно улучшить метрику.\n",
    "2. Наилучших результатов метрики удалось добиться применением модели Случайный лес (до и после применения методов базовой оптимизации).\n",
    "3. RandomizedSearchCV дает лучшие результаты по затраченному времени чем GridSearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Продвинутая оптимизация гиперпараметров модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Hyperopt - Логистическая регрессия**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Версия Hyperopt : 0.2.7\n"
     ]
    }
   ],
   "source": [
    "# проверим установленную версию Hyperopt\n",
    "print(\"Версия Hyperopt : {}\".format(hyperopt.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зададим пространство поиска гиперпараметров\n",
    "# Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "space = {'penalty': hp.choice('penalty',['l2', 'none']) ,\n",
    "    'solver': hp.choice('solver',['newton_cg', 'sag']),\n",
    "    'C': hp.quniform('C',0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1)}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зафиксируем random_state\n",
    "random_state = 42\n",
    "def hyperopt_lr(params, cv=5, X=X_train, y=y_train, random_state=random_state):\n",
    "    # функция получает комбинацию гиперпараметров в \"params\"\n",
    "    params = {'penalty': params['penalty'], \n",
    "              'solver': params['solver'], \n",
    "             'C': params['min_samples_leaf']\n",
    "              }\n",
    "  \n",
    "    # используем эту комбинацию для построения модели\n",
    "    model = linear_model.LogisticRegression(\n",
    "        **params,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    # обучаем модель\n",
    "    model.fit(X, y)\n",
    "    score = metrics.f1_score(y, model.predict(X))\n",
    "\n",
    "    # метрику необходимо минимизировать, поэтому ставим знак минус\n",
    "    return -score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ap_quniform_sampler() got multiple values for argument 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:5\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/hyperopt/fmin.py:540\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    537\u001b[0m     fn \u001b[39m=\u001b[39m __objective_fmin_wrapper(fn)\n\u001b[1;32m    539\u001b[0m \u001b[39mif\u001b[39;00m allow_trials_fmin \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(trials, \u001b[39m\"\u001b[39m\u001b[39mfmin\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 540\u001b[0m     \u001b[39mreturn\u001b[39;00m trials\u001b[39m.\u001b[39;49mfmin(\n\u001b[1;32m    541\u001b[0m         fn,\n\u001b[1;32m    542\u001b[0m         space,\n\u001b[1;32m    543\u001b[0m         algo\u001b[39m=\u001b[39;49malgo,\n\u001b[1;32m    544\u001b[0m         max_evals\u001b[39m=\u001b[39;49mmax_evals,\n\u001b[1;32m    545\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    546\u001b[0m         loss_threshold\u001b[39m=\u001b[39;49mloss_threshold,\n\u001b[1;32m    547\u001b[0m         max_queue_len\u001b[39m=\u001b[39;49mmax_queue_len,\n\u001b[1;32m    548\u001b[0m         rstate\u001b[39m=\u001b[39;49mrstate,\n\u001b[1;32m    549\u001b[0m         pass_expr_memo_ctrl\u001b[39m=\u001b[39;49mpass_expr_memo_ctrl,\n\u001b[1;32m    550\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    551\u001b[0m         catch_eval_exceptions\u001b[39m=\u001b[39;49mcatch_eval_exceptions,\n\u001b[1;32m    552\u001b[0m         return_argmin\u001b[39m=\u001b[39;49mreturn_argmin,\n\u001b[1;32m    553\u001b[0m         show_progressbar\u001b[39m=\u001b[39;49mshow_progressbar,\n\u001b[1;32m    554\u001b[0m         early_stop_fn\u001b[39m=\u001b[39;49mearly_stop_fn,\n\u001b[1;32m    555\u001b[0m         trials_save_file\u001b[39m=\u001b[39;49mtrials_save_file,\n\u001b[1;32m    556\u001b[0m     )\n\u001b[1;32m    558\u001b[0m \u001b[39mif\u001b[39;00m trials \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    559\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(trials_save_file):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/hyperopt/base.py:671\u001b[0m, in \u001b[0;36mTrials.fmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[39m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[39m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \u001b[39m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfmin\u001b[39;00m \u001b[39mimport\u001b[39;00m fmin\n\u001b[0;32m--> 671\u001b[0m \u001b[39mreturn\u001b[39;00m fmin(\n\u001b[1;32m    672\u001b[0m     fn,\n\u001b[1;32m    673\u001b[0m     space,\n\u001b[1;32m    674\u001b[0m     algo\u001b[39m=\u001b[39;49malgo,\n\u001b[1;32m    675\u001b[0m     max_evals\u001b[39m=\u001b[39;49mmax_evals,\n\u001b[1;32m    676\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    677\u001b[0m     loss_threshold\u001b[39m=\u001b[39;49mloss_threshold,\n\u001b[1;32m    678\u001b[0m     trials\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    679\u001b[0m     rstate\u001b[39m=\u001b[39;49mrstate,\n\u001b[1;32m    680\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    681\u001b[0m     max_queue_len\u001b[39m=\u001b[39;49mmax_queue_len,\n\u001b[1;32m    682\u001b[0m     allow_trials_fmin\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,  \u001b[39m# -- prevent recursion\u001b[39;49;00m\n\u001b[1;32m    683\u001b[0m     pass_expr_memo_ctrl\u001b[39m=\u001b[39;49mpass_expr_memo_ctrl,\n\u001b[1;32m    684\u001b[0m     catch_eval_exceptions\u001b[39m=\u001b[39;49mcatch_eval_exceptions,\n\u001b[1;32m    685\u001b[0m     return_argmin\u001b[39m=\u001b[39;49mreturn_argmin,\n\u001b[1;32m    686\u001b[0m     show_progressbar\u001b[39m=\u001b[39;49mshow_progressbar,\n\u001b[1;32m    687\u001b[0m     early_stop_fn\u001b[39m=\u001b[39;49mearly_stop_fn,\n\u001b[1;32m    688\u001b[0m     trials_save_file\u001b[39m=\u001b[39;49mtrials_save_file,\n\u001b[1;32m    689\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/hyperopt/fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    583\u001b[0m rval\u001b[39m.\u001b[39mcatch_eval_exceptions \u001b[39m=\u001b[39m catch_eval_exceptions\n\u001b[1;32m    585\u001b[0m \u001b[39m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m rval\u001b[39m.\u001b[39;49mexhaust()\n\u001b[1;32m    588\u001b[0m \u001b[39mif\u001b[39;00m return_argmin:\n\u001b[1;32m    589\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(trials\u001b[39m.\u001b[39mtrials) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/hyperopt/fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexhaust\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    363\u001b[0m     n_done \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials)\n\u001b[0;32m--> 364\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_evals \u001b[39m-\u001b[39;49m n_done, block_until_done\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49masynchronous)\n\u001b[1;32m    365\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[1;32m    366\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/hyperopt/fmin.py:278\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[1;32m    274\u001b[0m \u001b[39m# Based on existing trials and the domain, use `algo` to probe in\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[39m# new hp points. Save the results of those inspections into\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[39m# `new_trials`. This is the core of `run`, all the rest is just\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[39m# processes orchestration\u001b[39;00m\n\u001b[0;32m--> 278\u001b[0m new_trials \u001b[39m=\u001b[39m algo(\n\u001b[1;32m    279\u001b[0m     new_ids, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdomain, trials, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrstate\u001b[39m.\u001b[39;49mintegers(\u001b[39m2\u001b[39;49m \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m \u001b[39m31\u001b[39;49m \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m    280\u001b[0m )\n\u001b[1;32m    281\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(new_ids) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(new_trials)\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(new_trials):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/hyperopt/tpe.py:859\u001b[0m, in \u001b[0;36msuggest\u001b[0;34m(new_ids, domain, trials, seed, prior_weight, n_startup_jobs, n_EI_candidates, gamma, verbose)\u001b[0m\n\u001b[1;32m    857\u001b[0m t0 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    858\u001b[0m \u001b[39m# use build_posterior_wrapper to create the pyll nodes\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m observed, observed_loss, posterior \u001b[39m=\u001b[39m build_posterior_wrapper(\n\u001b[1;32m    860\u001b[0m     domain, prior_weight, gamma\n\u001b[1;32m    861\u001b[0m )\n\u001b[1;32m    862\u001b[0m tt \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m t0\n\u001b[1;32m    863\u001b[0m \u001b[39mif\u001b[39;00m verbose:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/hyperopt/tpe.py:813\u001b[0m, in \u001b[0;36mbuild_posterior_wrapper\u001b[0;34m(domain, prior_weight, gamma)\u001b[0m\n\u001b[1;32m    810\u001b[0m observed \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39midxs\u001b[39m\u001b[39m\"\u001b[39m: pyll\u001b[39m.\u001b[39mLiteral(), \u001b[39m\"\u001b[39m\u001b[39mvals\u001b[39m\u001b[39m\"\u001b[39m: pyll\u001b[39m.\u001b[39mLiteral()}\n\u001b[1;32m    811\u001b[0m observed_loss \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39midxs\u001b[39m\u001b[39m\"\u001b[39m: pyll\u001b[39m.\u001b[39mLiteral(), \u001b[39m\"\u001b[39m\u001b[39mvals\u001b[39m\u001b[39m\"\u001b[39m: pyll\u001b[39m.\u001b[39mLiteral()}\n\u001b[0;32m--> 813\u001b[0m posterior \u001b[39m=\u001b[39m build_posterior(\n\u001b[1;32m    814\u001b[0m     \u001b[39m# -- vectorized clone of bandit template\u001b[39;49;00m\n\u001b[1;32m    815\u001b[0m     domain\u001b[39m.\u001b[39;49mvh\u001b[39m.\u001b[39;49mv_expr,\n\u001b[1;32m    816\u001b[0m     \u001b[39m# -- this dict and next represent prior dists\u001b[39;49;00m\n\u001b[1;32m    817\u001b[0m     domain\u001b[39m.\u001b[39;49mvh\u001b[39m.\u001b[39;49midxs_by_label(),\n\u001b[1;32m    818\u001b[0m     domain\u001b[39m.\u001b[39;49mvh\u001b[39m.\u001b[39;49mvals_by_label(),\n\u001b[1;32m    819\u001b[0m     observed[\u001b[39m\"\u001b[39;49m\u001b[39midxs\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    820\u001b[0m     observed[\u001b[39m\"\u001b[39;49m\u001b[39mvals\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    821\u001b[0m     observed_loss[\u001b[39m\"\u001b[39;49m\u001b[39midxs\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    822\u001b[0m     observed_loss[\u001b[39m\"\u001b[39;49m\u001b[39mvals\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    823\u001b[0m     pyll\u001b[39m.\u001b[39;49mLiteral(gamma),\n\u001b[1;32m    824\u001b[0m     pyll\u001b[39m.\u001b[39;49mLiteral(\u001b[39mfloat\u001b[39;49m(prior_weight)),\n\u001b[1;32m    825\u001b[0m )\n\u001b[1;32m    827\u001b[0m \u001b[39mreturn\u001b[39;00m observed, observed_loss, posterior\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/hyperopt/tpe.py:705\u001b[0m, in \u001b[0;36mbuild_posterior\u001b[0;34m(specs, prior_idxs, prior_vals, obs_idxs, obs_vals, obs_loss_idxs, obs_loss_vals, oloss_gamma, prior_weight)\u001b[0m\n\u001b[1;32m    703\u001b[0m b_args \u001b[39m=\u001b[39m [obs_below, prior_weight] \u001b[39m+\u001b[39m aa\n\u001b[1;32m    704\u001b[0m named_args \u001b[39m=\u001b[39m {kw: memo[arg] \u001b[39mfor\u001b[39;00m (kw, arg) \u001b[39min\u001b[39;00m node\u001b[39m.\u001b[39mnamed_args}\n\u001b[0;32m--> 705\u001b[0m b_post \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49mb_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnamed_args)\n\u001b[1;32m    706\u001b[0m a_args \u001b[39m=\u001b[39m [obs_above, prior_weight] \u001b[39m+\u001b[39m aa\n\u001b[1;32m    707\u001b[0m a_post \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39ma_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnamed_args)\n",
      "\u001b[0;31mTypeError\u001b[0m: ap_quniform_sampler() got multiple values for argument 'size'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# начинаем подбор гиперпараметров\n",
    "\n",
    "trials = Trials() # используется для логирования результатов\n",
    "\n",
    "best=fmin(hyperopt_lr, # наша функция \n",
    "          space=space, # пространство гиперпараметров\n",
    "          algo=tpe.suggest, # алгоритм оптимизации, установлен по умолчанию, задавать необязательно\n",
    "          max_evals=20, # максимальное количество итераций\n",
    "          trials=trials, # логирование результатов\n",
    "          rstate=np.random.default_rng(random_state) # фиксируем для повторяемости результата\n",
    "         )\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(best))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Hyperopt - Случайный лес**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зададим пространство поиска гиперпараметров\n",
    "space={'n_estimators': hp.quniform('n_estimators', 100, 200, 1),\n",
    "       'max_depth' : hp.quniform('max_depth', 15, 26, 1),\n",
    "       'min_samples_leaf': hp.quniform('min_samples_leaf', 2, 10, 1)\n",
    "      }\n",
    "# зафксируем random_state\n",
    "random_state = 42\n",
    "def hyperopt_rf(params, cv=5, X=X_train, y=y_train, random_state=random_state):\n",
    "    # функция получает комбинацию гиперпараметров в \"params\"\n",
    "    params = {'n_estimators': int(params['n_estimators']), \n",
    "              'max_depth': int(params['max_depth']), \n",
    "             'min_samples_leaf': int(params['min_samples_leaf'])\n",
    "              }\n",
    "  \n",
    "    # используем эту комбинацию для построения модели\n",
    "    model = ensemble.RandomForestClassifier(**params, random_state=random_state)\n",
    "\n",
    "    # обучаем модель\n",
    "    model.fit(X, y)\n",
    "    score = metrics.f1_score(y, model.predict(X))\n",
    "    \n",
    "    # обучать модель можно также с помощью кросс-валидации\n",
    "    # применим  cross validation с тем же количеством фолдов\n",
    "    # score = cross_val_score(model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\n",
    "\n",
    "    # метрику необходимо минимизировать, поэтому ставим знак минус\n",
    "    return -score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1 µs, total: 5 µs\n",
      "Wall time: 13.8 µs\n",
      "100%|██████████| 20/20 [00:43<00:00,  2.18s/trial, best loss: -0.9901719901719903]\n",
      "Наилучшие значения гиперпараметров {'max_depth': 22.0, 'min_samples_leaf': 2.0, 'n_estimators': 125.0}\n"
     ]
    }
   ],
   "source": [
    "%time # начинаем подбор гиперпараметров\n",
    "\n",
    "trials = Trials() # используется для логирования результатов\n",
    "\n",
    "best=fmin(hyperopt_rf, # наша функция \n",
    "          space=space, # пространство гиперпараметров\n",
    "          algo=tpe.suggest, # алгоритм оптимизации, установлен по умолчанию, задавать необязательно\n",
    "          max_evals=20, # максимальное количество итераций\n",
    "          trials=trials, # логирование результатов\n",
    "          rstate=np.random.seed(random_state)# фиксируем для повторяемости результата\n",
    "         )\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score на тестовом наборе: 0.80\n"
     ]
    }
   ],
   "source": [
    "# рассчитаем точность для тестовой выборки\n",
    "model = ensemble.RandomForestClassifier(\n",
    "    random_state=random_state, \n",
    "    n_estimators=int(best['n_estimators']),\n",
    "    max_depth=int(best['max_depth']),\n",
    "    min_samples_leaf=int(best['min_samples_leaf'])\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С Hyperopt метрику улучшить не удалось."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Optuna - Случайный лес**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Версия Optuna: 3.0.0\n"
     ]
    }
   ],
   "source": [
    "# Проверим версию \n",
    "print(\"Версия Optuna: {}\".format(optuna.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_rf(trial):\n",
    "    # задаем пространства поиска гиперпараметров\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
    "    max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
    "\n",
    "    # создаем модель\n",
    "    model = ensemble.RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                            max_depth=max_depth,\n",
    "                                            min_samples_leaf=min_samples_leaf,\n",
    "                                            random_state=random_state)\n",
    "    # обучаем модель\n",
    "    model.fit(X_train, y_train)\n",
    "    score = metrics.f1_score(y_train, model.predict(X_train))\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-09 21:49:51,507]\u001b[0m A new study created in memory with name: RandomForestClassifier\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:49:53,394]\u001b[0m Trial 0 finished with value: 0.9564157269125266 and parameters: {'n_estimators': 118, 'max_depth': 25, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.9564157269125266.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:49:55,933]\u001b[0m Trial 1 finished with value: 0.9740458015267175 and parameters: {'n_estimators': 157, 'max_depth': 29, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.9740458015267175.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:49:57,502]\u001b[0m Trial 2 finished with value: 0.9459541984732824 and parameters: {'n_estimators': 118, 'max_depth': 11, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.9740458015267175.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:49:58,959]\u001b[0m Trial 3 finished with value: 0.9040097205346294 and parameters: {'n_estimators': 115, 'max_depth': 21, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.9740458015267175.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:50:00,888]\u001b[0m Trial 4 finished with value: 0.9031866464339908 and parameters: {'n_estimators': 147, 'max_depth': 23, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.9740458015267175.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:50:02,281]\u001b[0m Trial 5 finished with value: 0.8998178506375227 and parameters: {'n_estimators': 106, 'max_depth': 22, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.9740458015267175.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:50:04,912]\u001b[0m Trial 6 finished with value: 0.9752671755725191 and parameters: {'n_estimators': 177, 'max_depth': 26, 'min_samples_leaf': 3}. Best is trial 6 with value: 0.9752671755725191.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:50:06,646]\u001b[0m Trial 7 finished with value: 0.9340659340659341 and parameters: {'n_estimators': 140, 'max_depth': 11, 'min_samples_leaf': 3}. Best is trial 6 with value: 0.9752671755725191.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:50:08,351]\u001b[0m Trial 8 finished with value: 0.9544760158875649 and parameters: {'n_estimators': 115, 'max_depth': 17, 'min_samples_leaf': 4}. Best is trial 6 with value: 0.9752671755725191.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:50:10,753]\u001b[0m Trial 9 finished with value: 0.930246725555894 and parameters: {'n_estimators': 175, 'max_depth': 16, 'min_samples_leaf': 6}. Best is trial 6 with value: 0.9752671755725191.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:50:13,808]\u001b[0m Trial 10 finished with value: 0.9302042060347455 and parameters: {'n_estimators': 199, 'max_depth': 30, 'min_samples_leaf': 6}. Best is trial 6 with value: 0.9752671755725191.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:50:16,439]\u001b[0m Trial 11 finished with value: 0.9911015648972077 and parameters: {'n_estimators': 170, 'max_depth': 30, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.9911015648972077.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:50:19,294]\u001b[0m Trial 12 finished with value: 0.99079754601227 and parameters: {'n_estimators': 178, 'max_depth': 27, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.9911015648972077.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:50:22,107]\u001b[0m Trial 13 finished with value: 0.9911070223857713 and parameters: {'n_estimators': 177, 'max_depth': 27, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.9911070223857713.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:50:24,873]\u001b[0m Trial 14 finished with value: 0.9463087248322148 and parameters: {'n_estimators': 195, 'max_depth': 30, 'min_samples_leaf': 5}. Best is trial 13 with value: 0.9911070223857713.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:50:26,916]\u001b[0m Trial 15 finished with value: 0.9210206561360875 and parameters: {'n_estimators': 161, 'max_depth': 26, 'min_samples_leaf': 7}. Best is trial 13 with value: 0.9911070223857713.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:50:29,611]\u001b[0m Trial 16 finished with value: 0.9886676875957121 and parameters: {'n_estimators': 166, 'max_depth': 18, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.9911070223857713.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:50:32,188]\u001b[0m Trial 17 finished with value: 0.9213483146067415 and parameters: {'n_estimators': 185, 'max_depth': 28, 'min_samples_leaf': 7}. Best is trial 13 with value: 0.9911070223857713.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:50:34,255]\u001b[0m Trial 18 finished with value: 0.9564422784038988 and parameters: {'n_estimators': 133, 'max_depth': 24, 'min_samples_leaf': 4}. Best is trial 13 with value: 0.9911070223857713.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:50:36,865]\u001b[0m Trial 19 finished with value: 0.9356903383114904 and parameters: {'n_estimators': 188, 'max_depth': 14, 'min_samples_leaf': 5}. Best is trial 13 with value: 0.9911070223857713.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:50:39,117]\u001b[0m Trial 20 finished with value: 0.8951686417502278 and parameters: {'n_estimators': 172, 'max_depth': 19, 'min_samples_leaf': 10}. Best is trial 13 with value: 0.9911070223857713.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:50:42,079]\u001b[0m Trial 21 finished with value: 0.9914057704112953 and parameters: {'n_estimators': 186, 'max_depth': 28, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.9914057704112953.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:50:45,244]\u001b[0m Trial 22 finished with value: 0.9911015648972077 and parameters: {'n_estimators': 189, 'max_depth': 28, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.9914057704112953.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:50:48,048]\u001b[0m Trial 23 finished with value: 0.974969474969475 and parameters: {'n_estimators': 167, 'max_depth': 30, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.9914057704112953.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:50:51,179]\u001b[0m Trial 24 finished with value: 0.9914057704112953 and parameters: {'n_estimators': 183, 'max_depth': 27, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.9914057704112953.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:50:54,073]\u001b[0m Trial 25 finished with value: 0.9755799755799756 and parameters: {'n_estimators': 185, 'max_depth': 24, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.9914057704112953.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:50:56,322]\u001b[0m Trial 26 finished with value: 0.9554878048780487 and parameters: {'n_estimators': 156, 'max_depth': 27, 'min_samples_leaf': 4}. Best is trial 21 with value: 0.9914057704112953.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:50:59,417]\u001b[0m Trial 27 finished with value: 0.9910961007061714 and parameters: {'n_estimators': 194, 'max_depth': 21, 'min_samples_leaf': 2}. Best is trial 21 with value: 0.9914057704112953.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:51:02,173]\u001b[0m Trial 28 finished with value: 0.9469835466179158 and parameters: {'n_estimators': 182, 'max_depth': 25, 'min_samples_leaf': 5}. Best is trial 21 with value: 0.9914057704112953.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:51:04,450]\u001b[0m Trial 29 finished with value: 0.9740458015267175 and parameters: {'n_estimators': 150, 'max_depth': 28, 'min_samples_leaf': 3}. Best is trial 21 with value: 0.9914057704112953.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:51:07,320]\u001b[0m Trial 30 finished with value: 0.9582952815829529 and parameters: {'n_estimators': 196, 'max_depth': 25, 'min_samples_leaf': 4}. Best is trial 21 with value: 0.9914057704112953.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:51:10,294]\u001b[0m Trial 31 finished with value: 0.9914110429447852 and parameters: {'n_estimators': 190, 'max_depth': 28, 'min_samples_leaf': 2}. Best is trial 31 with value: 0.9914110429447852.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:51:13,305]\u001b[0m Trial 32 finished with value: 0.9917152500767107 and parameters: {'n_estimators': 191, 'max_depth': 27, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.9917152500767107.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:51:16,153]\u001b[0m Trial 33 finished with value: 0.975 and parameters: {'n_estimators': 191, 'max_depth': 29, 'min_samples_leaf': 3}. Best is trial 32 with value: 0.9917152500767107.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:51:19,174]\u001b[0m Trial 34 finished with value: 0.9917101627264354 and parameters: {'n_estimators': 200, 'max_depth': 26, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.9917152500767107.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:51:22,479]\u001b[0m Trial 35 finished with value: 0.9914057704112953 and parameters: {'n_estimators': 200, 'max_depth': 23, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.9917152500767107.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:51:25,558]\u001b[0m Trial 36 finished with value: 0.9743276283618583 and parameters: {'n_estimators': 200, 'max_depth': 22, 'min_samples_leaf': 3}. Best is trial 32 with value: 0.9917152500767107.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:51:28,377]\u001b[0m Trial 37 finished with value: 0.958828911253431 and parameters: {'n_estimators': 190, 'max_depth': 26, 'min_samples_leaf': 4}. Best is trial 32 with value: 0.9917152500767107.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:51:30,652]\u001b[0m Trial 38 finished with value: 0.9727911953531031 and parameters: {'n_estimators': 125, 'max_depth': 29, 'min_samples_leaf': 3}. Best is trial 32 with value: 0.9917152500767107.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:51:33,031]\u001b[0m Trial 39 finished with value: 0.909423604757548 and parameters: {'n_estimators': 180, 'max_depth': 24, 'min_samples_leaf': 8}. Best is trial 32 with value: 0.9917152500767107.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:51:36,252]\u001b[0m Trial 40 finished with value: 0.975 and parameters: {'n_estimators': 193, 'max_depth': 29, 'min_samples_leaf': 3}. Best is trial 32 with value: 0.9917152500767107.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:51:39,344]\u001b[0m Trial 41 finished with value: 0.9914057704112953 and parameters: {'n_estimators': 184, 'max_depth': 27, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.9917152500767107.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:51:42,839]\u001b[0m Trial 42 finished with value: 0.9914057704112953 and parameters: {'n_estimators': 187, 'max_depth': 26, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.9917152500767107.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:51:46,292]\u001b[0m Trial 43 finished with value: 0.9914057704112953 and parameters: {'n_estimators': 200, 'max_depth': 23, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.9917152500767107.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:51:49,204]\u001b[0m Trial 44 finished with value: 0.974969474969475 and parameters: {'n_estimators': 172, 'max_depth': 28, 'min_samples_leaf': 3}. Best is trial 32 with value: 0.9917152500767107.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:51:52,372]\u001b[0m Trial 45 finished with value: 0.9914057704112953 and parameters: {'n_estimators': 197, 'max_depth': 23, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.9917152500767107.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:51:55,496]\u001b[0m Trial 46 finished with value: 0.9904878797177048 and parameters: {'n_estimators': 196, 'max_depth': 21, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.9917152500767107.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:51:57,088]\u001b[0m Trial 47 finished with value: 0.9722476364745349 and parameters: {'n_estimators': 105, 'max_depth': 25, 'min_samples_leaf': 3}. Best is trial 32 with value: 0.9917152500767107.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:52:00,469]\u001b[0m Trial 48 finished with value: 0.9914057704112953 and parameters: {'n_estimators': 192, 'max_depth': 25, 'min_samples_leaf': 2}. Best is trial 32 with value: 0.9917152500767107.\u001b[0m\n",
      "\u001b[32m[I 2022-10-09 21:52:03,118]\u001b[0m Trial 49 finished with value: 0.9582444376714417 and parameters: {'n_estimators': 180, 'max_depth': 22, 'min_samples_leaf': 4}. Best is trial 32 with value: 0.9917152500767107.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 10s, sys: 1.18 s, total: 2min 11s\n",
      "Wall time: 2min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# cоздаем объект исследования\n",
    "# можем напрямую указать, что нам необходимо максимизировать метрику direction=\"maximize\"\n",
    "study = optuna.create_study(study_name=\"RandomForestClassifier\", direction=\"maximize\")\n",
    "# ищем лучшую комбинацию гиперпараметров n_trials раз\n",
    "study.optimize(optuna_rf, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие значения гиперпараметров {'n_estimators': 173, 'max_depth': 24, 'min_samples_leaf': 2}\n",
      "f1_score на обучающем наборе: 0.99\n"
     ]
    }
   ],
   "source": [
    "# выводим результаты на обучающей выборке\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(study.best_params))\n",
    "print(\"f1_score на обучающем наборе: {:.2f}\".format(study.best_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score на тестовом наборе: 0.81\n"
     ]
    }
   ],
   "source": [
    "# рассчитаем точность для тестовой выборки\n",
    "model = ensemble.RandomForestClassifier(**study.best_params,random_state=random_state, )\n",
    "model.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрику удалось улучшить методом  Optuna для модели Random Forest. Оптимальные параметры: n_estimators (количество деревьев) = 173, max_depth (максимальная глубина дерева) = 24, min_samples_leaf (минимальное количество объектов в листе) = 2. Значение метрики F1 = 0.81."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "217422af06b81c4546264fc7608183ee0663ede64c8b5bb9fe5794fe0d5e4579"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
